import type { MastraLanguageModel } from '../../index.js';
import type { MastraMessageV2 } from '../../message-list/index.js';
import type { InputProcessor } from '../index.js';
/**
 * Confidence scores for each moderation category (0-1)
 */
export interface ModerationCategoryScores {
    hate?: number;
    'hate/threatening'?: number;
    harassment?: number;
    'harassment/threatening'?: number;
    'self-harm'?: number;
    'self-harm/intent'?: number;
    'self-harm/instructions'?: number;
    sexual?: number;
    'sexual/minors'?: number;
    violence?: number;
    'violence/graphic'?: number;
    [customCategory: string]: number | undefined;
}
/**
 * Result structure for moderation
 */
export interface ModerationResult {
    category_scores?: ModerationCategoryScores;
    reason?: string;
}
/**
 * Configuration options for ModerationInputProcessor
 */
export interface ModerationOptions {
    /** Model configuration for the moderation agent */
    model: MastraLanguageModel;
    /**
     * Categories to check for moderation.
     * If not specified, uses default OpenAI categories.
     */
    categories?: string[];
    /**
     * Confidence threshold for flagging (0-1, default: 0.5)
     * Content is flagged if any category score exceeds this threshold
     */
    threshold?: number;
    /**
     * Strategy when content is flagged:
     * - 'block': Reject the entire input with an error (default)
     * - 'warn': Log warning but allow content through
     * - 'filter': Remove flagged messages but continue with remaining
     */
    strategy?: 'block' | 'warn' | 'filter';
    /**
     * Custom moderation instructions for the agent
     * If not provided, uses default instructions based on categories
     */
    instructions?: string;
    /**
     * Whether to include confidence scores in logs (default: false)
     * Useful for tuning thresholds and debugging
     */
    includeScores?: boolean;
}
/**
 * ModerationInputProcessor uses an internal Mastra agent to evaluate content
 * against configurable moderation categories for content safety.
 *
 * Provides flexible moderation with custom categories, thresholds, and strategies
 * while maintaining compatibility with OpenAI's moderation API structure.
 */
export declare class ModerationInputProcessor implements InputProcessor {
    readonly name = "moderation";
    private moderationAgent;
    private categories;
    private threshold;
    private strategy;
    private includeScores;
    private static readonly DEFAULT_CATEGORIES;
    constructor(options: ModerationOptions);
    process(args: {
        messages: MastraMessageV2[];
        abort: (reason?: string) => never;
    }): Promise<MastraMessageV2[]>;
    /**
     * Moderate content using the internal agent
     */
    private moderateContent;
    /**
     * Determine if content is flagged based on category scores above threshold
     */
    private isModerationFlagged;
    /**
     * Handle flagged content based on strategy
     */
    private handleFlaggedContent;
    /**
     * Extract text content from message for moderation
     */
    private extractTextContent;
    /**
     * Create default moderation instructions
     */
    private createDefaultInstructions;
    /**
     * Create moderation prompt for the agent
     */
    private createModerationPrompt;
}
//# sourceMappingURL=moderation.d.ts.map